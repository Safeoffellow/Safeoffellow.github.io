<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>检测兴趣点</title>
      <link href="/2021/082436518.html"/>
      <url>/2021/082436518.html</url>
      
        <content type="html"><![CDATA[<h1 id="检查兴趣点"><a href="#检查兴趣点" class="headerlink" title="检查兴趣点"></a>检查兴趣点</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>计算机视觉领域，<strong>兴趣点</strong>（也称关键点和特征点）的概念已经运用到了目标识别、图像配准、视觉跟踪、三维重建等。</p><p>原理：从图像中选取某些特征点并对图像进行局部分析（即提取局部特征），而非观察整幅图像（即提取全局特征）。</p><p>重要特征：<strong>视觉不变性</strong></p><p>无论拍摄时采用了<strong>什么视角、尺度和方位</strong>，理想情况下同一个场景或目标都要检测到特征点。</p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ol><li><p>cv::Keypoint 类，封装了每个检测到的<strong>特征点的属性</strong></p></li><li><p>cv::Feature2D 确保其他类包含以下格式的delete方法：</p><pre class=" language-c++"><code class="language-c++">void detect( cv::InputArray image,  std::vector<KeyPoint>& keypoints,  cv::InputArray mask ); void detect( cv::InputArrayOfArrays images,  std::vector<std::vector<KeyPoint> >& keypoints,  cv::InputArrayOfArrays masks );</code></pre><p>第二种方法可以从包含图像的<strong>容器中检测兴趣点</strong>。此类还包含特征描述符的计算方法。</p></li><li><p>图像上画关键点的通用函数</p><pre class=" language-C++"><code class="language-C++">cv::drawKeypoints(image, // 原始图像 keypoints, // 关键点的向量 image, // 输出图像 cv::Scalar(255,255,255), // 关键点的颜色 cv::DrawMatchesFlags::DRAW_OVER_OUTIMG); // 画图标志</code></pre></li><li><p>检测兴趣点步骤：</p><ol><li>定义关键点向量和对应的特征检测器</li><li>使用detect函数获得关键点</li><li>使用drawKeypoints函数绘制关键点</li></ol></li></ol><h2 id="检测图像中的角点"><a href="#检测图像中的角点" class="headerlink" title="检测图像中的角点"></a>检测图像中的角点</h2><p>角点是很容易在图像中定位的局部特征，大量存在于人造物体中（例如墙壁、门窗等）。角点的价值在于它是<strong>两条边缘线的接合点</strong>， <strong>是一种二维特征</strong>，可以被<strong>精确地定位</strong>（即使是子像素级精度）。 与此相反的是位于均匀区域或物体轮廓上的点以及在同一物体的不同图像上很难重复精确定位的点。 Harris特征检测是检测角点的经典方法。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>OpenCV中检测Harris角点的基本函数是cv::cornerHarris，调用时输入一幅图像，返回结果时一个浮点数型图像，其中每个像素表示角点强度，再对输出图像阈值化，以获得检测角点的集合。</p><pre class=" language-c++"><code class="language-c++">// 检测 Harris 角点cv::Mat cornerStrength; cv::cornerHarris(image, // 输入图像 cornerStrength, // 角点强度的图像 3, // 邻域尺寸 3, // 口径尺寸 0.01); // Harris 参数// 对角点强度阈值化cv::Mat harrisCorners; double threshold= 0.0001; cv::threshold(cornerStrength,harrisCorners,  threshold,255,cv::THRESH_BINARY);</code></pre><h2 id="FAST快速检测特征"><a href="#FAST快速检测特征" class="headerlink" title="FAST快速检测特征"></a>FAST快速检测特征</h2><p>FAST（Features from Accelerated Segment Test，加速分割测试获得特征）</p><h2 id="尺度不变特征检测"><a href="#尺度不变特征检测" class="headerlink" title="尺度不变特征检测"></a>尺度不变特征检测</h2><p>为了解决视觉不变性，计算机视觉引入了尺度不变特征：</p><p>不仅在<strong>任何尺度下拍摄</strong>的物体都能检测到<strong>一致的关键点</strong>，而且每个被检测的特征点都<strong>对应一个尺度因子</strong>。</p><h3 id="实现：SURF特征"><a href="#实现：SURF特征" class="headerlink" title="实现：SURF特征"></a>实现：SURF特征</h3><p>SURF特征检测属于<strong>opencv_contrib库</strong>，需要<strong>xfeatures2d模块</strong>。检测兴趣点时，线创建检测器实例再调用检测方法。</p><pre class=" language-c++"><code class="language-c++">// 创建 SURF 特征检测器对象cv::Ptr<cv::xfeatures2d::SurfFeatureDetector> ptrSURF =  cv::xfeatures2d::SurfFeatureDetector::create(2000.0); // 检测关键点ptrSURF->detect(image, keypoints);// 画出关键点，包括尺度和方向信息cv::drawKeypoints(image, // 原始图像 keypoints, // 关键点的向量 featureImage, // 结果图像 cv::Scalar(255,255,255), // 点的颜色 cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS);</code></pre><p>注：在调用cv::drawKeypoints 函数，时要采用 cv::Draw MatchesFlags::DRAW_RICH_KEYPOINTS 标志以<strong>显示相关的尺度因子</strong></p><p>这里使用 cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS 标志得到了<strong>关键点的圆</strong>，并且圆的尺寸与<strong>每个特征计算得到的尺度成正比</strong>。为了使特征具有旋转不变性，SURF 还让每个特征<strong>关联了一个方向</strong>，由每个圆内的<strong>辐射线表示</strong>。</p><h3 id="扩展-SIFT特征检测算法"><a href="#扩展-SIFT特征检测算法" class="headerlink" title="扩展: SIFT特征检测算法"></a>扩展: SIFT特征检测算法</h3><p>SIFT(Scale-Invariant Feature Transform，尺度不变特征转换)</p><p>SIFT特征检测过程于SURF非常相似：</p><pre class=" language-c++"><code class="language-c++">// 构建 SIFT 特征检测器实例cv::Ptr<cv::xfeatures2d::SiftFeatureDetector> ptrSIFT =  cv::xfeatures2d::SiftFeatureDetector::create(); // 检测关键点ptrSIFT->detect(image, keypoints);</code></pre><p>运用这两种特征检测算法，可以使用</p><p><code>cv::xfeatures2d::SurfFeatureDetector </code>和 <code>cv::xfeatures2d::SiftFeature Detector</code>类作为兴趣点检测器。</p><p>同样，也可以使用<code>cv::xfeatures2d::SURF</code>和<code>cv::xfeatures2d::SIFT</code> 类（它们的格式是一样的）。SURF 和 SIFT 运算既包含了<strong>检测功能</strong>，还可以<strong>描述兴趣点</strong>。</p><h2 id="多尺度FAST特征检测"><a href="#多尺度FAST特征检测" class="headerlink" title="多尺度FAST特征检测"></a>多尺度FAST特征检测</h2><p>FAST时一种快速检测图像关键点的方法。使用SURF和SIFT算法时，侧重点在于设计尺度不变特征。而再之后提出的兴趣点检测新方法，<strong>既能快速检测，又不随尺度改变而变化</strong>。</p><h3 id="实现：BRISK检测法"><a href="#实现：BRISK检测法" class="headerlink" title="实现：BRISK检测法"></a>实现：BRISK检测法</h3><p>BRISK检测法基于FAST特征检测法</p><p>首先创建检测器实例，然后对一幅图像调用detect方法：</p><pre class=" language-c++"><code class="language-c++">// 构造 BRISK 特征检测器对象cv::Ptr<cv::BRISK> ptrBRISK = cv::BRISK::create(); // 检测关键点ptrBRISK->detect(image, keypoints);</code></pre><p>原理：为了在不同尺度下检测兴趣点，该算法首先通过两个下采样过程<strong>构建一个图像金字塔</strong>。第一个过程从原始图像尺寸开始，然后每一图层（八度）<strong>减少一半</strong>。第二个过程先将<strong>原始图像的尺寸除以 1.5</strong> 得到第一幅图像，然后在这幅图像的基础上<strong>每一层减少一半</strong>，两个过程产生的<strong>图层交替在一起</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-image/image/202108241523212.png" alt="图像金字塔"></p><p>在金字塔的所有图像上应用FAST特征检测器。BRISK算法的关键在于，金字塔<strong>各个图层具有不同的分辨率</strong>。为了精确定位每个关键点，算法需要在<strong>尺度和空间</strong>两个方面进行插值</p><p>BRISK检测器有两个主要参数，一个是<strong>判断FAST关键点的阈值</strong>，一个是图像金字塔中<strong>生成八度的数量</strong></p><h3 id="扩展：ORB特征检测算法"><a href="#扩展：ORB特征检测算法" class="headerlink" title="扩展：ORB特征检测算法"></a>扩展：ORB特征检测算法</h3><p>ORB代表<strong>定向FAST和旋转BRIEF</strong>。第一层表示<strong>关键点检测</strong>，第二层表示<strong>ORB算法提供的描述子</strong>。</p><p>OBR先创建一个图像金字塔。它由一系列图层组成，每个图层都是用<strong>固定的缩放因子</strong>对前一个图层下采样得到的。（默认参数：<strong>用8个尺度，缩放因子为1.2</strong>）。在具有关键点评分位置接受N个强度最大的关键点，关键点评分用<strong>Harris角点强度衡量方法</strong>。</p><p>OBR检测器原理基于每个被检测的兴趣点总是<strong>关联了一个方向</strong>。这个信息可用于校准不同图像中检测到的关键点描述子。</p><p>检测方法：</p><pre class=" language-c++"><code class="language-c++">// 构造 ORB 特征检测器对象cv::Ptr<cv::ORB> ptrORB =  cv::ORB::create(75, // 关键点的总数 1.2, // 图层之间的缩放因子 8); // 金字塔的图层数量// 检测关键点ptrORB->detect(image, keypoints);</code></pre>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>齐次坐标系“</title>
      <link href="/2021/082362855.html"/>
      <url>/2021/082362855.html</url>
      
        <content type="html"><![CDATA[<h1 id="关于齐次坐标系的理解"><a href="#关于齐次坐标系的理解" class="headerlink" title="关于齐次坐标系的理解"></a>关于齐次坐标系的理解</h1><h2 id="序言：两条平行线可以相交于一点"><a href="#序言：两条平行线可以相交于一点" class="headerlink" title="序言：两条平行线可以相交于一点"></a>序言：两条平行线可以相交于一点</h2><p>在<strong>欧氏几何空间</strong>，同一平面的两条平行线<strong>不能相交</strong>。</p><p>但在<strong>透视空间</strong>里，两条平行线<strong>可以相交</strong>，例如：火车轨道随着我们的视线越来越窄，最后两条平行线在无穷远处交于一点。</p><p>欧氏空间（or笛卡尔坐标系）描述2D/3D几何非常合适，但不适合处理透视空间的问题（事实上，<strong>欧氏几何是透视几何的一个子集合</strong>），2维笛卡尔坐标系可以表示为（x，y）。</p><p>若一个点在无穷远处，这个点的坐标为（∞，∞）。平行线在透视空间的无穷远处交于一点，但在<strong>欧氏空间却不能</strong>。</p><h2 id="方法：齐次坐标系"><a href="#方法：齐次坐标系" class="headerlink" title="方法：齐次坐标系"></a>方法：齐次坐标系</h2><p>定义：齐次坐标就是用N+1维来表示N维坐标</p><p>即在一个2D笛卡尔坐标末尾加上一个<strong>额外的变量w</strong>来形成2D齐次坐标，因此，一个点（X，Y）在齐次坐标里面变成了（x, y, w），并且有</p><p><code>X = x/w</code></p><p><code>Y = y/w</code></p><p>例如，笛卡尔坐标系下（1， 2）的齐次坐标系可以表示为（1， 2， 1），如果或点（1，2）移动到无限远处。</p><p>笛卡尔坐标系下它为（∞，∞）</p><p>它的齐次坐标系为（1， 2， 0），因为（1/0, 2/0） = （∞， ∞），因此可以不用∞来表示一个无穷远处的点了。</p><h2 id="来由：为什么叫齐次坐标系"><a href="#来由：为什么叫齐次坐标系" class="headerlink" title="来由：为什么叫齐次坐标系"></a>来由：为什么叫齐次坐标系</h2><p>把齐次坐标转化为笛卡尔坐标的方法是<strong>前面n-1坐标分量分别除以最后一个分量</strong>即可。如图：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-image/image/202108231124829.png" alt="P1 齐次坐标与笛卡尔坐标转换 "></p><p>在转换中，会发现一个特性：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-image/image/202108231126653.png" alt="P2 特殊转换"></p><p>你会发现(1, 2, 3), (2, 4, 6) 和(4, 8, 12)对应同一个笛卡尔坐标系点 (1/3, 2/3)，<strong>任何标量的乘积</strong>，例如**(1a, 2a, 3a)** 对应 笛卡尔空间里面的(1/3, 2/3) 。</p><p>因此，这些点是“<strong>齐次的</strong>”，因为他们<strong>代表了笛卡尔坐标系里面的同一个点</strong>。换句话说，齐次坐标有<strong>规模不变性</strong>。</p><h2 id="证明：两条直线可以相交"><a href="#证明：两条直线可以相交" class="headerlink" title="证明：两条直线可以相交"></a>证明：两条直线可以相交</h2><p>有如下方程组：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-image/image/202108231129254.png" alt="P3 方程组"></p><p>在笛卡尔坐标系中，该方程无解，因为C≠D，如果C=D，就为同一条直线。</p><p>在透视空间里，用齐次坐标x/w, y/w代替x, y</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-image/image/202108231132946.png" alt="P4 坐标转换"></p><p>因此，现在有一个解（x, y, 0 ），两条直线相交于(x, y, 0)， 这个点在无穷远处。</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>描述和匹配兴趣点</title>
      <link href="/2021/081947708.html"/>
      <url>/2021/081947708.html</url>
      
        <content type="html"><![CDATA[<h1 id="描述和匹配兴趣点"><a href="#描述和匹配兴趣点" class="headerlink" title="描述和匹配兴趣点"></a>描述和匹配兴趣点</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>每一个关键点都具有<strong>足够的独特性</strong>：如果一个物体在一幅图像中被检测到关键点，那么<strong>同一个物体</strong>在<strong>其他图像</strong>中也会检测到<strong>同一个关键点</strong>。而且一些<strong>复杂的兴趣点检测器</strong>可以在关键点上设置<strong>缩放因子和方向</strong>等。</p><p>为了进行基于兴趣点的图像分析，需要构建多种表征方式，精确地描述每个关键点。而<strong>描述子</strong>就是用来描述关键点的重要数据。</p><p>描述子描述了一个<strong>关键点和它的邻域</strong>，好的描述子要具有足够的<strong>独特性</strong>，能<strong>唯一</strong>地表示图像中的每个关键点。</p><h2 id="局部模板匹配"><a href="#局部模板匹配" class="headerlink" title="局部模板匹配"></a>局部模板匹配</h2><p>通过特征点匹配，可以将一幅图像的点集和另一幅图像（或一批图像）的点集关联起来。如果两个点集对应着现实世界中的同一个场景元素，它们就应该是匹配的。</p><p>单凭当个像素判断两个关键点的相似度肯定不够，因此要在匹配过程中考虑每个关键点<strong>周围的图像块（邻域）</strong></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>最常见的图像块是边长为<strong>奇数的正方形</strong>，关键点的位置是<strong>正方形的中心</strong>。通过比较块内像素强度值来衡量两个正方形图像块的相似度。常见的方案是采用差的平方和（Sum of Squared Differences, SSD）算法。</p><pre class=" language-c++"><code class="language-c++">//定义特征检测器cv::Ptr<cv::FeatureDetector> ptrDetector;ptrDetector = cv::FastFeatureDetector::create(80);//检测关键点ptrDetector->detect(image1, keypoints1);ptrDetector->detect(image2, keypoints2);</code></pre>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《操作系统真象还原笔记》</title>
      <link href="/2021/081764532.html"/>
      <url>/2021/081764532.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Opencv 动态背景下的目标跟踪识别</title>
      <link href="/2021/081444430.html"/>
      <url>/2021/081444430.html</url>
      
        <content type="html"><![CDATA[<h1 id="【Opencv】动态背景下运动目标检测"><a href="#【Opencv】动态背景下运动目标检测" class="headerlink" title="【Opencv】动态背景下运动目标检测"></a>【Opencv】动态背景下运动目标检测</h1><h2 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h2><p>动态背景下的运动目标检测算法分为两类：一是光流法，二是背景运动补偿差分法。</p><p>光流法的原理是<strong>利用聚类法</strong>将<strong>运动矢量场分为前景和背景</strong>两类，从而得到运动目标。但光流法对<strong>噪声及光照变化敏感，且算法复杂，计算量大</strong>，不适合实时性要求高的场合。背景运动补偿差分法的原理是<strong>拍摄场景与摄像机相对运动</strong>引起的背景运动<strong>进行建模补偿</strong>，<strong>再进行差分</strong>得到运动目标。</p><h2 id="二、背景运动补偿差分法"><a href="#二、背景运动补偿差分法" class="headerlink" title="二、背景运动补偿差分法"></a>二、背景运动补偿差分法</h2><p>背景运动补偿差分法首先通过<strong>匹配相邻帧的提取出来的特征</strong>，然后再将匹配的特征点<strong>代入建立的背景运动模型中求解出该模型参数</strong>，利用背景模型对参考帧做<strong>背景运动补偿再检测运动</strong>，使得运动目标与动态背景分离从而准确获得每个运动目标区域。</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Safeoffellow.github.io/img/202108141740904.png" alt="P2.1 动态背景下运动目标检测流程图"></p><ol><li>参数模型</li></ol>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Opencv】静态背景下的目标跟踪识别</title>
      <link href="/2021/081353946.html"/>
      <url>/2021/081353946.html</url>
      
        <content type="html"><![CDATA[<h1 id="【Opencv】静态背景下运动目标检测"><a href="#【Opencv】静态背景下运动目标检测" class="headerlink" title="【Opencv】静态背景下运动目标检测"></a>【Opencv】静态背景下运动目标检测</h1><h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><p>由于采集到的视频序列图像上<strong>通常会含有噪声</strong>，为了提高准确率需要在检测之前<strong>增强图像质量和消除图像噪声的预处理</strong>。</p><h3 id="一、灰度化处理"><a href="#一、灰度化处理" class="headerlink" title="一、灰度化处理"></a>一、灰度化处理</h3><h3 id="二、去噪处理"><a href="#二、去噪处理" class="headerlink" title="二、去噪处理"></a>二、去噪处理</h3><p>由于<strong>天气变化、光照变化、采集设备、图像数据传输、摄像机抖动等造成获得图像中夹杂着各种噪声</strong>，致使图像质量下降。因此去噪处理至关重要。图像去噪可采用<strong>傅里叶变换和低通滤波技术的频率域法</strong>。</p><p>滤波操作时为了对图像进行初步的优化处理，滤波方法包括中值滤波、均值滤波等。</p><h4 id="（1）均值滤波"><a href="#（1）均值滤波" class="headerlink" title="（1）均值滤波"></a>（1）均值滤波</h4><p>均值滤波是最简单的噪声消除方法。用某像素周围 n * n (n = 3, 5, 7，……) 像素范围的<strong>平均值代替该像素的方法</strong>。将均值滤波处理后的图像表示为 <strong>g(x, y)</strong> ， 其计算可由下式所示：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161004373.png" alt="P1 均值滤波计算公式"></p><p>上式中，n定义为模板窗口中<strong>像素的数目</strong>。均值滤波对高斯噪声有很好的处理效果，但均值滤波<strong>会使图像模糊，特别是轮廓边缘不清晰</strong>。</p><h4 id="（2）中值滤波"><a href="#（2）中值滤波" class="headerlink" title="（2）中值滤波"></a>（2）中值滤波</h4><p>中值滤波是指输出值取<strong>滤波器窗口内像素灰度值排列顺序</strong>的<strong>中间值</strong>的滤波器。具体处理过程，是选某一形状和尺寸大小的窗口模板，再利用窗口模板，对需要处理的图像进行窗口内像素值</p><h2 id="运动目标检测算法"><a href="#运动目标检测算法" class="headerlink" title="运动目标检测算法"></a>运动目标检测算法</h2><h3 id="背景差分法"><a href="#背景差分法" class="headerlink" title="背景差分法"></a>背景差分法</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>利用输入的<strong>当前帧与预留的背景帧</strong>进行差分，对差分结果进行<strong>阈值分割</strong>，从而检测运动目标，获得运动目标估计区域。</p><h4 id="具体计算"><a href="#具体计算" class="headerlink" title="具体计算"></a>具体计算</h4><p>流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161004478.png" alt="P1 背景差分法流程图"></p><p>背景差分法的数学模型如下：</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161005399.png" alt="P2 背景差分法计算公式"></p><p>改进之处：</p><p>传统的背景差分法是将运动目标<strong>还未出现时采集的图像作为背景图像</strong>，但是因为场景中的光照变化、树叶扰动以及雨雪天气等干扰存在，也有可能运动目标在场景中由运动状态变为静止，被当成背景处理等因素，是得目标检测<strong>误差很大</strong>。为了使背景更新策略能够<strong>适应复杂场景</strong>，需要要求此背景更新策略能够随背景变化自适应地更新背景模型，提高准确率。<strong>中值模型、均值模型、单高斯模型、混合高斯模型</strong>等是目前主要的背景建模方法。</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The First</title>
      <link href="/2021/081029930.html"/>
      <url>/2021/081029930.html</url>
      
        <content type="html"><![CDATA[<p>​    终于！两天终于把博客搭建好了，感谢<a href="https://www.bilibili.com/video/BV1Yb411a7ty">羊哥的教学视频</a>，视频十分详细，在手把手教学下完成了个人博客的初始搭建。</p><p>第一篇博客，我来总结一下，这几天获得的一些经验</p><h2 id="如何生成一篇博客"><a href="#如何生成一篇博客" class="headerlink" title="如何生成一篇博客"></a>如何生成一篇博客</h2><p>生成一篇博客：</p><ol><li>hexo n “博客名称”           ——创建一篇信的博客——markdown格式</li><li>找到生成的markdown文件所在位置并编辑它</li><li>hexo g                                ——生成你更改的配置</li><li>hexo s                                 ——启动博客，完成预览</li><li>hexo d                                 ——上传至我的github仓库</li></ol><p><strong>注：</strong>在出错或完成一次生成后，记得用hexo clean清理缓存再用hexo g生成。</p><ol start="6"><li><p>一篇博客的初始化设置</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108160959427.png" alt="The First P1"></p></li></ol><h2 id="VPN的小教训"><a href="#VPN的小教训" class="headerlink" title="VPN的小教训"></a>VPN的小教训</h2><p>之前为了更快速进入github，下了一个vpn翻墙，电脑关机的时候，忘了退出vpn软件了，导致第二天开机时，wife网络一直连接失败。</p><p>在经过万能的百度搜索后，找到了解决方法；</p><ol><li><p>首先先打开Windows设置</p></li><li><p>然后点开 <strong>更新和安全</strong>，再点击其中的<strong>疑难解答</strong>，进入后点击<strong>其他疑难解答</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161000050.png" alt="The First P2"></p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161001392.png" alt="The First P3"></p></li><li><p>然后点击进入<strong>Internet连接</strong>，进入Internet问题检查</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161002145.png" alt="The First P4"></p></li><li><p>检查后返回了这样的结果</p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161002886.png" alt="The First P5"></p></li><li><p>搜索百度后，得知开启VPN的时候，打开了代理服务器，我们把它关掉就能正常上网了。先打开 <strong>“网络和Internet设置”</strong>，找到<strong>代理</strong>，<strong>关闭手动代理设置</strong></p><p><img src="https://cdn.jsdelivr.net/gh/Safeoffellow/Hexo-Image/image/202108161002999.png" alt="The First P6"></p></li></ol><p>PS：唉，这网络搞了我两个小时，总结下来就是，<strong>翻墙有风险，用VPN需谨慎！</strong></p>]]></content>
      
      
      <categories>
          
          <category> Living </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
            <tag> recording </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/080916107.html"/>
      <url>/2021/080916107.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
