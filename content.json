{"meta":{"title":"Charlotte","subtitle":"Charlotte","description":"风行水上，自然成纹","author":"Safeoffellow","url":"http://Safeoffellow.github.io","root":"/"},"pages":[{"title":"404","date":"2021-08-09T09:12:28.000Z","updated":"2021-08-09T09:13:30.629Z","comments":true,"path":"404/index.html","permalink":"http://safeoffellow.github.io/404/index.html","excerpt":"","text":""},{"title":"about","date":"2021-08-09T09:02:32.000Z","updated":"2021-08-09T09:02:46.299Z","comments":true,"path":"about/index.html","permalink":"http://safeoffellow.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-08-09T08:40:03.000Z","updated":"2021-08-09T08:40:03.515Z","comments":true,"path":"categories/index-1.html","permalink":"http://safeoffellow.github.io/categories/index-1.html","excerpt":"","text":""},{"title":"categories","date":"2021-08-09T08:39:46.000Z","updated":"2021-08-09T08:59:43.343Z","comments":true,"path":"categories/index.html","permalink":"http://safeoffellow.github.io/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2021-08-09T09:03:10.000Z","updated":"2021-08-09T09:03:22.307Z","comments":true,"path":"contact/index.html","permalink":"http://safeoffellow.github.io/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-08-09T09:00:45.000Z","updated":"2021-08-09T09:01:06.982Z","comments":true,"path":"tags/index.html","permalink":"http://safeoffellow.github.io/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-08-09T09:10:24.000Z","updated":"2021-08-09T09:10:41.257Z","comments":true,"path":"friends/index.html","permalink":"http://safeoffellow.github.io/friends/index.html","excerpt":"","text":""},{"title":"cartoon","date":"2021-08-23T07:56:34.000Z","updated":"2021-08-23T08:25:00.041Z","comments":true,"path":"cartoon/index.html","permalink":"http://safeoffellow.github.io/cartoon/index.html","excerpt":"","text":""},{"title":"food","date":"2021-08-23T07:56:47.000Z","updated":"2021-08-23T08:25:37.882Z","comments":true,"path":"food/index.html","permalink":"http://safeoffellow.github.io/food/index.html","excerpt":"","text":""},{"title":"game","date":"2021-08-23T07:57:14.000Z","updated":"2021-08-23T08:24:27.249Z","comments":true,"path":"game/index.html","permalink":"http://safeoffellow.github.io/game/index.html","excerpt":"","text":""},{"title":"movies","date":"2021-08-23T07:56:25.000Z","updated":"2021-08-23T07:58:49.662Z","comments":true,"path":"movies/index.html","permalink":"http://safeoffellow.github.io/movies/index.html","excerpt":"","text":""}],"posts":[{"title":"检测兴趣点","slug":"检测兴趣点","date":"2021-08-24T02:00:49.000Z","updated":"2021-08-24T08:11:29.794Z","comments":true,"path":"2021/082436518.html","link":"","permalink":"http://safeoffellow.github.io/2021/082436518.html","excerpt":"","text":"检查兴趣点介绍计算机视觉领域，兴趣点（也称关键点和特征点）的概念已经运用到了目标识别、图像配准、视觉跟踪、三维重建等。 原理：从图像中选取某些特征点并对图像进行局部分析（即提取局部特征），而非观察整幅图像（即提取全局特征）。 重要特征：视觉不变性 无论拍摄时采用了什么视角、尺度和方位，理想情况下同一个场景或目标都要检测到特征点。 基础知识 cv::Keypoint 类，封装了每个检测到的特征点的属性 cv::Feature2D 确保其他类包含以下格式的delete方法： void detect( cv::InputArray image, std::vector& keypoints, cv::InputArray mask ); void detect( cv::InputArrayOfArrays images, std::vector& keypoints, cv::InputArrayOfArrays masks ); 第二种方法可以从包含图像的容器中检测兴趣点。此类还包含特征描述符的计算方法。 图像上画关键点的通用函数 cv::drawKeypoints(image, // 原始图像 keypoints, // 关键点的向量 image, // 输出图像 cv::Scalar(255,255,255), // 关键点的颜色 cv::DrawMatchesFlags::DRAW_OVER_OUTIMG); // 画图标志 检测兴趣点步骤： 定义关键点向量和对应的特征检测器 使用detect函数获得关键点 使用drawKeypoints函数绘制关键点 检测图像中的角点角点是很容易在图像中定位的局部特征，大量存在于人造物体中（例如墙壁、门窗等）。角点的价值在于它是两条边缘线的接合点， 是一种二维特征，可以被精确地定位（即使是子像素级精度）。 与此相反的是位于均匀区域或物体轮廓上的点以及在同一物体的不同图像上很难重复精确定位的点。 Harris特征检测是检测角点的经典方法。 实现OpenCV中检测Harris角点的基本函数是cv::cornerHarris，调用时输入一幅图像，返回结果时一个浮点数型图像，其中每个像素表示角点强度，再对输出图像阈值化，以获得检测角点的集合。 // 检测 Harris 角点 cv::Mat cornerStrength; cv::cornerHarris(image, // 输入图像 cornerStrength, // 角点强度的图像 3, // 邻域尺寸 3, // 口径尺寸 0.01); // Harris 参数 // 对角点强度阈值化 cv::Mat harrisCorners; double threshold = 0.0001; cv::threshold(cornerStrength,harrisCorners, threshold,255,cv::THRESH_BINARY); FAST快速检测特征FAST（Features from Accelerated Segment Test，加速分割测试获得特征） 尺度不变特征检测为了解决视觉不变性，计算机视觉引入了尺度不变特征： 不仅在任何尺度下拍摄的物体都能检测到一致的关键点，而且每个被检测的特征点都对应一个尺度因子。 实现：SURF特征SURF特征检测属于opencv_contrib库，需要xfeatures2d模块。检测兴趣点时，线创建检测器实例再调用检测方法。 // 创建 SURF 特征检测器对象 cv::Ptr ptrSURF = cv::xfeatures2d::SurfFeatureDetector::create(2000.0); // 检测关键点 ptrSURF->detect(image, keypoints); // 画出关键点，包括尺度和方向信息 cv::drawKeypoints(image, // 原始图像 keypoints, // 关键点的向量 featureImage, // 结果图像 cv::Scalar(255,255,255), // 点的颜色 cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS); 注：在调用cv::drawKeypoints 函数，时要采用 cv::Draw MatchesFlags::DRAW_RICH_KEYPOINTS 标志以显示相关的尺度因子 这里使用 cv::DrawMatchesFlags::DRAW_RICH_KEYPOINTS 标志得到了关键点的圆，并且圆的尺寸与每个特征计算得到的尺度成正比。为了使特征具有旋转不变性，SURF 还让每个特征关联了一个方向，由每个圆内的辐射线表示。 扩展: SIFT特征检测算法SIFT(Scale-Invariant Feature Transform，尺度不变特征转换) SIFT特征检测过程于SURF非常相似： // 构建 SIFT 特征检测器实例 cv::Ptr ptrSIFT = cv::xfeatures2d::SiftFeatureDetector::create(); // 检测关键点 ptrSIFT->detect(image, keypoints); 运用这两种特征检测算法，可以使用 cv::xfeatures2d::SurfFeatureDetector 和 cv::xfeatures2d::SiftFeature Detector类作为兴趣点检测器。 同样，也可以使用cv::xfeatures2d::SURF和cv::xfeatures2d::SIFT 类（它们的格式是一样的）。SURF 和 SIFT 运算既包含了检测功能，还可以描述兴趣点。 多尺度FAST特征检测FAST时一种快速检测图像关键点的方法。使用SURF和SIFT算法时，侧重点在于设计尺度不变特征。而再之后提出的兴趣点检测新方法，既能快速检测，又不随尺度改变而变化。 实现：BRISK检测法BRISK检测法基于FAST特征检测法 首先创建检测器实例，然后对一幅图像调用detect方法： // 构造 BRISK 特征检测器对象 cv::Ptr ptrBRISK = cv::BRISK::create(); // 检测关键点 ptrBRISK->detect(image, keypoints); 原理：为了在不同尺度下检测兴趣点，该算法首先通过两个下采样过程构建一个图像金字塔。第一个过程从原始图像尺寸开始，然后每一图层（八度）减少一半。第二个过程先将原始图像的尺寸除以 1.5 得到第一幅图像，然后在这幅图像的基础上每一层减少一半，两个过程产生的图层交替在一起。 在金字塔的所有图像上应用FAST特征检测器。BRISK算法的关键在于，金字塔各个图层具有不同的分辨率。为了精确定位每个关键点，算法需要在尺度和空间两个方面进行插值 BRISK检测器有两个主要参数，一个是判断FAST关键点的阈值，一个是图像金字塔中生成八度的数量 扩展：ORB特征检测算法ORB代表定向FAST和旋转BRIEF。第一层表示关键点检测，第二层表示ORB算法提供的描述子。 OBR先创建一个图像金字塔。它由一系列图层组成，每个图层都是用固定的缩放因子对前一个图层下采样得到的。（默认参数：用8个尺度，缩放因子为1.2）。在具有关键点评分位置接受N个强度最大的关键点，关键点评分用Harris角点强度衡量方法。 OBR检测器原理基于每个被检测的兴趣点总是关联了一个方向。这个信息可用于校准不同图像中检测到的关键点描述子。 检测方法： // 构造 ORB 特征检测器对象 cv::Ptr ptrORB = cv::ORB::create(75, // 关键点的总数 1.2, // 图层之间的缩放因子 8); // 金字塔的图层数量 // 检测关键点 ptrORB->detect(image, keypoints);","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"author":"Safeoffellow"},{"title":"齐次坐标系“","slug":"齐次坐标系“","date":"2021-08-23T02:57:40.000Z","updated":"2021-08-23T03:37:21.943Z","comments":true,"path":"2021/082362855.html","link":"","permalink":"http://safeoffellow.github.io/2021/082362855.html","excerpt":"","text":"关于齐次坐标系的理解序言：两条平行线可以相交于一点在欧氏几何空间，同一平面的两条平行线不能相交。 但在透视空间里，两条平行线可以相交，例如：火车轨道随着我们的视线越来越窄，最后两条平行线在无穷远处交于一点。 欧氏空间（or笛卡尔坐标系）描述2D/3D几何非常合适，但不适合处理透视空间的问题（事实上，欧氏几何是透视几何的一个子集合），2维笛卡尔坐标系可以表示为（x，y）。 若一个点在无穷远处，这个点的坐标为（∞，∞）。平行线在透视空间的无穷远处交于一点，但在欧氏空间却不能。 方法：齐次坐标系定义：齐次坐标就是用N+1维来表示N维坐标 即在一个2D笛卡尔坐标末尾加上一个额外的变量w来形成2D齐次坐标，因此，一个点（X，Y）在齐次坐标里面变成了（x, y, w），并且有 X = x/w Y = y/w 例如，笛卡尔坐标系下（1， 2）的齐次坐标系可以表示为（1， 2， 1），如果或点（1，2）移动到无限远处。 笛卡尔坐标系下它为（∞，∞） 它的齐次坐标系为（1， 2， 0），因为（1/0, 2/0） = （∞， ∞），因此可以不用∞来表示一个无穷远处的点了。 来由：为什么叫齐次坐标系把齐次坐标转化为笛卡尔坐标的方法是前面n-1坐标分量分别除以最后一个分量即可。如图： 在转换中，会发现一个特性： 你会发现(1, 2, 3), (2, 4, 6) 和(4, 8, 12)对应同一个笛卡尔坐标系点 (1/3, 2/3)，任何标量的乘积，例如**(1a, 2a, 3a)** 对应 笛卡尔空间里面的(1/3, 2/3) 。 因此，这些点是“齐次的”，因为他们代表了笛卡尔坐标系里面的同一个点。换句话说，齐次坐标有规模不变性。 证明：两条直线可以相交有如下方程组： 在笛卡尔坐标系中，该方程无解，因为C≠D，如果C=D，就为同一条直线。 在透视空间里，用齐次坐标x/w, y/w代替x, y 因此，现在有一个解（x, y, 0 ），两条直线相交于(x, y, 0)， 这个点在无穷远处。","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"author":"Safeoffellow"},{"title":"描述和匹配兴趣点","slug":"描述和匹配兴趣点","date":"2021-08-19T09:41:03.000Z","updated":"2021-08-24T10:13:36.216Z","comments":true,"path":"2021/081947708.html","link":"","permalink":"http://safeoffellow.github.io/2021/081947708.html","excerpt":"","text":"描述和匹配兴趣点介绍每一个关键点都具有足够的独特性：如果一个物体在一幅图像中被检测到关键点，那么同一个物体在其他图像中也会检测到同一个关键点。而且一些复杂的兴趣点检测器可以在关键点上设置缩放因子和方向等。 为了进行基于兴趣点的图像分析，需要构建多种表征方式，精确地描述每个关键点。而描述子就是用来描述关键点的重要数据。 描述子描述了一个关键点和它的邻域，好的描述子要具有足够的独特性，能唯一地表示图像中的每个关键点。 基本知识DMatchDMatch数据结构本质上包含两个索引 第一个索引指向第一个关键点向量中的元素 第二个索引指向第二个关键点向量中匹配上的特征点。 还包含一个数值，表示两个已匹配的描述子之间的差距。运算符 &lt; 可以用于比较两个 cv::DMatch实例。 matchTemplate图像分析中，一个常见的任务是检测图像中是否存在特定的图案或物体。 实现方法是把包含该物体的小图像作为模板，然后指定图像上搜索与模板相似的部分。搜索的范围通常仅限于可能发现该物体的区域 在这个区域上滑动模板，并在每个像素位置计算相似度。 drawMatches该函数能把两幅图像拼接起来，然后用线条连接每个对应的点。 // 画出匹配结果 cv::Mat matchImage; cv::drawMatches(image1,keypoints1, // 第一幅图像 image2,keypoints2, // 第二幅图像 matches, // 匹配项的向量 cv::Scalar(255,255,255), // 线条颜色 cv::Scalar(255,255,255)); // 点的颜色 局部模板匹配通过特征点匹配，可以将一幅图像的点集和另一幅图像（或一批图像）的点集关联起来。如果两个点集对应着现实世界中的同一个场景元素，它们就应该是匹配的。 单凭当个像素判断两个关键点的相似度肯定不够，因此要在匹配过程中考虑每个关键点周围的图像块（邻域） 实现最常见的图像块是边长为奇数的正方形，关键点的位置是正方形的中心。通过比较块内像素强度值来衡量两个正方形图像块的相似度。常见的方案是采用差的平方和（Sum of Squared Differences, SSD）算法。 //定义特征检测器 cv::Ptr ptrDetector; ptrDetector = cv::FastFeatureDetector::create(80); //检测关键点 ptrDetector->detect(image1, keypoints1); ptrDetector->detect(image2, keypoints2); 然后定义一个特定大小的矩形，用于表示每个关键点周围的图像块 // 定义正方形的邻域 const int nsize(11); // 邻域的尺寸 cv::Rect neighborhood(0, 0, nsize, nsize); // 11×11 cv::Mat patch1; cv::Mat patch2; 将一幅图像的关键点与另一幅图像的全部关键点进行比较。在第二幅图像中找出与第一幅图像中的每个关键点最相似的图像块 // 在第二幅图像中找出与第一幅图像中的每个关键点最匹配的 cv::Mat result; std::vector matches; // 针对图像一的全部关键点 for (int i=0; icompute(image1,keypoints1,descriptors1); ptrFeature2D->compute(image2,keypoints2,descriptors2); 兴趣点描述子的计算结果是一个矩阵（即Mat），矩阵的行数是关键点容器的元素个数，每行是一个N维的描述子容器。两个特征点越相似，它们的描述子容器就会越接近。 接下来用描述子来进行关键点匹配。将第一幅图像的每个特征描述子向量与第二幅图像的全部特征描述子进行比较，把相似度最高的一对（即两个描述子向量之间的距离最短）保留下来，作为最佳匹配项。 Opencv中有一个BFMatch类可以实现，避免构建两个循环。 // 构造匹配器 cv::BFMatcher matcher(cv::NORM_L2); // 匹配两幅图像的描述子 std::vector matches; matcher.match(descriptors1,descriptors2, matches); PS: Feature2D类有一个很实用的函数，可在检查兴趣点的同时计算它们的描述子。调用方法为 ptrFeature2D->detectAndCompute(image, cv::noArray(), keypoints, descriptors); 提高匹配项质量交叉检查匹配项重新进行同一个匹配过程，但在第二次匹配时，将第二幅图象的每个关键点逐个与第一幅图像的全部关键点进行比较。只有在两个方向都匹配了一对关键点（即两个关键点互为最佳匹配）时，才认为是一个有效的匹配项。函数cv::BFMatcher提供了一个选项来使用这个策略。把有关标志设置为 true，函数就会对匹配进行双向的交叉检查： cv::BFMatcher matcher2(cv::NORM_L2, // 度量差距 true); // 交叉检查标志 用二值描述子匹配关键点由于描述子是浮点数类型的向量，导致对它们的操作将耗资巨大，为了减少内存使用、降低计算量，引入了二值描述子的概念。 常见的二值特征检测器有 ORB 和 BRISK 实现// 定义关键点容器和描述子 std::vector keypoints1; std::vector keypoints2; cv::Mat descriptors1; cv::Mat descriptors2; // 定义特征检测器/描述子 // Construct the ORB feature object cv::Ptr feature = cv::ORB::create(60); // 大约 60 个特征点 // 检测并描述关键点 // 检测 ORB 特征 feature->detectAndCompute(image1, cv::noArray(), keypoints1, descriptors1); feature->detectAndCompute(image2, cv::noArray(), keypoints2, descriptors2); // 构建匹配器 cv::BFMatcher matcher(cv::NORM_HAMMING); // 二值描述子一律使用 Hamming 规范 // 匹配两幅图像的描述子 std::vector matches; matcher.match(descriptors1, descriptors2, matches); 唯一的区别就是使用了Hamming规范（cv::NORM_HAMMING标志），通过统计不一致的位数来计算两个二值描述子的差值。","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"author":"Safeoffellow"},{"title":"《操作系统真象还原笔记》","slug":"《操作系统真象还原笔记》","date":"2021-08-17T08:44:15.000Z","updated":"2021-08-23T03:38:31.902Z","comments":true,"path":"2021/081764532.html","link":"","permalink":"http://safeoffellow.github.io/2021/081764532.html","excerpt":"","text":"","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://safeoffellow.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"author":"Safeoffellow"},{"title":"Opencv 动态背景下的目标跟踪识别","slug":"Opencv-动态背景下的目标跟踪识别","date":"2021-08-14T09:17:53.000Z","updated":"2021-08-23T03:39:56.298Z","comments":true,"path":"2021/081444430.html","link":"","permalink":"http://safeoffellow.github.io/2021/081444430.html","excerpt":"","text":"【Opencv】动态背景下运动目标检测一、引言动态背景下的运动目标检测算法分为两类：一是光流法，二是背景运动补偿差分法。 光流法的原理是利用聚类法将运动矢量场分为前景和背景两类，从而得到运动目标。但光流法对噪声及光照变化敏感，且算法复杂，计算量大，不适合实时性要求高的场合。背景运动补偿差分法的原理是拍摄场景与摄像机相对运动引起的背景运动进行建模补偿，再进行差分得到运动目标。 二、背景运动补偿差分法背景运动补偿差分法首先通过匹配相邻帧的提取出来的特征，然后再将匹配的特征点代入建立的背景运动模型中求解出该模型参数，利用背景模型对参考帧做背景运动补偿再检测运动，使得运动目标与动态背景分离从而准确获得每个运动目标区域。 参数模型","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"【Opencv】静态背景下的目标跟踪识别","slug":"Opencv-静态背景下的目标跟踪识别","date":"2021-08-13T09:59:36.000Z","updated":"2021-08-16T02:07:41.309Z","comments":true,"path":"2021/081353946.html","link":"","permalink":"http://safeoffellow.github.io/2021/081353946.html","excerpt":"","text":"【Opencv】静态背景下运动目标检测图像预处理由于采集到的视频序列图像上通常会含有噪声，为了提高准确率需要在检测之前增强图像质量和消除图像噪声的预处理。 一、灰度化处理二、去噪处理由于天气变化、光照变化、采集设备、图像数据传输、摄像机抖动等造成获得图像中夹杂着各种噪声，致使图像质量下降。因此去噪处理至关重要。图像去噪可采用傅里叶变换和低通滤波技术的频率域法。 滤波操作时为了对图像进行初步的优化处理，滤波方法包括中值滤波、均值滤波等。 （1）均值滤波均值滤波是最简单的噪声消除方法。用某像素周围 n * n (n = 3, 5, 7，……) 像素范围的平均值代替该像素的方法。将均值滤波处理后的图像表示为 g(x, y) ， 其计算可由下式所示： 上式中，n定义为模板窗口中像素的数目。均值滤波对高斯噪声有很好的处理效果，但均值滤波会使图像模糊，特别是轮廓边缘不清晰。 （2）中值滤波中值滤波是指输出值取滤波器窗口内像素灰度值排列顺序的中间值的滤波器。具体处理过程，是选某一形状和尺寸大小的窗口模板，再利用窗口模板，对需要处理的图像进行窗口内像素值 运动目标检测算法背景差分法原理利用输入的当前帧与预留的背景帧进行差分，对差分结果进行阈值分割，从而检测运动目标，获得运动目标估计区域。 具体计算流程图如下： 背景差分法的数学模型如下： 改进之处： 传统的背景差分法是将运动目标还未出现时采集的图像作为背景图像，但是因为场景中的光照变化、树叶扰动以及雨雪天气等干扰存在，也有可能运动目标在场景中由运动状态变为静止，被当成背景处理等因素，是得目标检测误差很大。为了使背景更新策略能够适应复杂场景，需要要求此背景更新策略能够随背景变化自适应地更新背景模型，提高准确率。中值模型、均值模型、单高斯模型、混合高斯模型等是目前主要的背景建模方法。","categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"author":"Safeoffellow"},{"title":"The First","slug":"The-First","date":"2021-08-10T08:21:16.000Z","updated":"2021-08-16T09:10:56.443Z","comments":true,"path":"2021/081029930.html","link":"","permalink":"http://safeoffellow.github.io/2021/081029930.html","excerpt":"","text":"​ 终于！两天终于把博客搭建好了，感谢羊哥的教学视频，视频十分详细，在手把手教学下完成了个人博客的初始搭建。 第一篇博客，我来总结一下，这几天获得的一些经验 如何生成一篇博客生成一篇博客： hexo n “博客名称” ——创建一篇信的博客——markdown格式 找到生成的markdown文件所在位置并编辑它 hexo g ——生成你更改的配置 hexo s ——启动博客，完成预览 hexo d ——上传至我的github仓库 注：在出错或完成一次生成后，记得用hexo clean清理缓存再用hexo g生成。 一篇博客的初始化设置 VPN的小教训之前为了更快速进入github，下了一个vpn翻墙，电脑关机的时候，忘了退出vpn软件了，导致第二天开机时，wife网络一直连接失败。 在经过万能的百度搜索后，找到了解决方法； 首先先打开Windows设置 然后点开 更新和安全，再点击其中的疑难解答，进入后点击其他疑难解答 然后点击进入Internet连接，进入Internet问题检查 检查后返回了这样的结果 搜索百度后，得知开启VPN的时候，打开了代理服务器，我们把它关掉就能正常上网了。先打开 “网络和Internet设置”，找到代理，关闭手动代理设置 PS：唉，这网络搞了我两个小时，总结下来就是，翻墙有风险，用VPN需谨慎！","categories":[{"name":"Living","slug":"Living","permalink":"http://safeoffellow.github.io/categories/Living/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://safeoffellow.github.io/tags/blog/"},{"name":"recording","slug":"recording","permalink":"http://safeoffellow.github.io/tags/recording/"}],"author":"Safeoffellow"},{"title":"Hello World","slug":"hello-world","date":"2021-08-09T02:07:47.698Z","updated":"2021-08-11T01:56:16.410Z","comments":true,"path":"2021/080916107.html","link":"","permalink":"http://safeoffellow.github.io/2021/080916107.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Study","slug":"Study","permalink":"http://safeoffellow.github.io/categories/Study/"},{"name":"Living","slug":"Living","permalink":"http://safeoffellow.github.io/categories/Living/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"http://safeoffellow.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"操作系统","slug":"操作系统","permalink":"http://safeoffellow.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"blog","slug":"blog","permalink":"http://safeoffellow.github.io/tags/blog/"},{"name":"recording","slug":"recording","permalink":"http://safeoffellow.github.io/tags/recording/"}]}